{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nimport random\nimport os\nfrom PIL import Image\n\nimport tensorflow as tf\n\nfrom keras.utils.np_utils import to_categorical \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve, roc_curve, auc\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.723814Z","iopub.execute_input":"2022-04-28T02:02:57.724060Z","iopub.status.idle":"2022-04-28T02:02:57.730407Z","shell.execute_reply.started":"2022-04-28T02:02:57.724033Z","shell.execute_reply":"2022-04-28T02:02:57.729712Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# LABELING","metadata":{}},{"cell_type":"code","source":"folder = \"../input/writing/train\"\n\ntrain_label = []                            # Label to train dataset\n\nfor img in os.listdir(folder):\n    if 'handwrit' in img:            \n        train_label.append((img, 1))\n    elif \"printout\" in img:\n        train_label.append((img, 0))\n        \n        \ndev_label = []                                      # Label to dev (development) dataset\nfolder1 = \"../input/writing/valid\"\n\nfor img in os.listdir(folder1):\n    if 'handwrit' in img:            \n        dev_label.append((img, 1))\n    elif \"printout\" in img:\n        dev_label.append((img, 0))\n\ndev_label= pd.DataFrame(dev_label)\ndev_label= dev_label.rename(columns={0:\"filename\", 1: \"categories\"})\n\ntrain_label= pd.DataFrame(train_label)\ntrain_label= train_label.rename(columns={0:\"filename\", 1: \"categories\"})     # Labeled our data.\n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.763948Z","iopub.execute_input":"2022-04-28T02:02:57.764234Z","iopub.status.idle":"2022-04-28T02:02:57.808445Z","shell.execute_reply.started":"2022-04-28T02:02:57.764206Z","shell.execute_reply":"2022-04-28T02:02:57.807793Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_label.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.809624Z","iopub.execute_input":"2022-04-28T02:02:57.809874Z","iopub.status.idle":"2022-04-28T02:02:57.819378Z","shell.execute_reply.started":"2022-04-28T02:02:57.809842Z","shell.execute_reply":"2022-04-28T02:02:57.818504Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"dev_label.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.846316Z","iopub.execute_input":"2022-04-28T02:02:57.846647Z","iopub.status.idle":"2022-04-28T02:02:57.854248Z","shell.execute_reply.started":"2022-04-28T02:02:57.846619Z","shell.execute_reply":"2022-04-28T02:02:57.853544Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_label[\"categories\"] = train_label[\"categories\"].replace({0: 'printout', 1: 'handwrit'}) \ndev_label[\"categories\"] = dev_label[\"categories\"].replace({0: 'printout', 1: 'handwrit'}) ","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.870714Z","iopub.execute_input":"2022-04-28T02:02:57.870999Z","iopub.status.idle":"2022-04-28T02:02:57.878975Z","shell.execute_reply.started":"2022-04-28T02:02:57.870973Z","shell.execute_reply":"2022-04-28T02:02:57.878329Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"dev = shuffle(dev_label, random_state=0)\ntrain = shuffle(train_label, random_state=0)\n\ntrain = train.reset_index(drop=True)\ndev = dev.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.897634Z","iopub.execute_input":"2022-04-28T02:02:57.897911Z","iopub.status.idle":"2022-04-28T02:02:57.906839Z","shell.execute_reply.started":"2022-04-28T02:02:57.897885Z","shell.execute_reply":"2022-04-28T02:02:57.906159Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train['categories'].value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:57.921757Z","iopub.execute_input":"2022-04-28T02:02:57.921958Z","iopub.status.idle":"2022-04-28T02:02:58.088170Z","shell.execute_reply.started":"2022-04-28T02:02:57.921935Z","shell.execute_reply":"2022-04-28T02:02:58.087542Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"dev['categories'].value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:58.089658Z","iopub.execute_input":"2022-04-28T02:02:58.089895Z","iopub.status.idle":"2022-04-28T02:02:58.259782Z","shell.execute_reply.started":"2022-04-28T02:02:58.089863Z","shell.execute_reply":"2022-04-28T02:02:58.259093Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# PREPARE TRAIN AND DEV SET","metadata":{}},{"cell_type":"code","source":"#Prepare train dataset\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.1,\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # dimesion reduction\n    rotation_range=5,  # randomly rotate images in the range 5 degrees\n    zoom_range = 0.1, # Randomly zoom image 10%\n    width_shift_range=0.1,  # randomly shift images horizontally 10%\n    height_shift_range=0.1,  # randomly shift images vertically 10%\n    horizontal_flip=False,  # randomly flip images\n    vertical_flip=False\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train, \n    \"../input/writing/train\", \n    x_col='filename',\n    y_col='categories',\n    target_size= (64,256),\n    class_mode='categorical',\n    batch_size=25,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:02:58.261226Z","iopub.execute_input":"2022-04-28T02:02:58.261515Z","iopub.status.idle":"2022-04-28T02:03:03.519817Z","shell.execute_reply.started":"2022-04-28T02:02:58.261478Z","shell.execute_reply":"2022-04-28T02:03:03.519083Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"\n#Prepare dev dataset\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dev, \n    \"../input/writing/valid\", \n    x_col='filename',\n    y_col='categories',\n    target_size=(64,256),\n    class_mode='categorical',\n    batch_size=25,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:03:03.522018Z","iopub.execute_input":"2022-04-28T02:03:03.522565Z","iopub.status.idle":"2022-04-28T02:03:04.516985Z","shell.execute_reply.started":"2022-04-28T02:03:03.522525Z","shell.execute_reply":"2022-04-28T02:03:04.516265Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#An example from train data\n\nexample_df = train_label.sample(n=1).reset_index(drop=True)\n\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"../input/writing/train\", \n    x_col='filename',\n    y_col='categories',\n    target_size=(64,256),\n    class_mode='categorical'\n)\n\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:03:04.518283Z","iopub.execute_input":"2022-04-28T02:03:04.518541Z","iopub.status.idle":"2022-04-28T02:03:06.034673Z","shell.execute_reply.started":"2022-04-28T02:03:04.518509Z","shell.execute_reply":"2022-04-28T02:03:06.032977Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# CREATE MODEL","metadata":{}},{"cell_type":"code","source":"#Create Model\n\nmodel = Sequential()\n\n#conv1\n\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5), padding = \"Same\", strides = (2,2), activation = \"relu\", input_shape = (64,256,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.5))\n\n#conv2\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3), padding = \"Same\", strides = (1,1), activation = \"relu\", input_shape = (64,256,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.5))\n\n#conv3\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = \"Same\", strides = (1,1), activation = \"relu\", input_shape = (64,256,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.5))\n\n#conv4\nmodel.add(Conv2D(filters = 64, kernel_size = (1,1), padding = \"Same\", strides = (1,1), activation = \"relu\", input_shape = (64,256,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.5))\n\n#FC1(Fully Connected) Layer\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n#FC2(Fully Connected) Layer\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))\n\n\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics= tf.keras.metrics.CategoricalAccuracy())\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:23:19.303906Z","iopub.execute_input":"2022-04-28T02:23:19.304160Z","iopub.status.idle":"2022-04-28T02:23:19.476061Z","shell.execute_reply.started":"2022-04-28T02:23:19.304130Z","shell.execute_reply":"2022-04-28T02:23:19.474760Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# MODEL ARCHITECTURE\n\n## Why RELU in Hidden Layer ?\n- The main advantage of the ReLU function, which is often used in Convolutional Neural Network (CNN) and middleware, is that it does not activate all neurons at the same time. \n- So if a neuron produces a negative value, it means that it will not be activated. \n- This allows ReLU to work more efficiently and faster than the Hyperbolic Tangent and Sigmoid function.\n- Therefore, ReLU is more preferred in multilayer neural networks.\n\n## Why filters started at 8 and increasing per each CONV layer ?\n- This is the first step process of extracting valuable feautres from an image\n- CNN compute input images with using filters and review the images with scans the image. \n- The layers which close to input layer will less, which closeto ouput layer will learn more filters.\n- İt must be multiples of 2\n\n## Why ı use padding ?\n- Use of Padding is increasing the model performance\n- If you dont use, the volume will decrease after each layer and the ınfromatıons may delete quickly.\n\n## Kernel Size\n- It determıne heigh and width of Convolution window\n- If ınput image larger than 128x128, start with 5x5 or 7x7 and decrease quickly and start work with 3x3. If not, stay with 3xor 1x1.\n- In this picture, I also used 1x1 as my picture is equal to 128x128\n\n## Strides\n- It determines how many pixels the filter will slide over the main page.\n\n## BatchNormalization\n- Batch normalization is a larger that allows every layer of the network to do learning more independently\n- Using Batch Normalization learning become efficient also it can be used as regulaziation to avoid overfitting of the model\n- It is often placed just after defining the Sequential model and after the convolution layer.\n\n## Pooling Layer\n- It work on feature map separately to create new set.\n- It used as 2x2 on 2x2 feature maps\n- I used Max Pooling becasue ıt generally used on visual data\n\n## Dropout Layer\n- Since all parameters are occupied into FCL (Fully Connected Layer), it causes overfitting.\n- Dropout is one of the techniquies that reduces overfitting.\n- It should be 0.5-0.8 in hidden layer\n- It should be around of 0.8 in input layer\n\n## Flatten Layer\n- It flatten the pooled of features into an input vector to processing in neural networks\n\n## FCL (Fully Connected Layer)\n- FCL looks like a regular neural network connecting all neurons and forms the last few layers in the network. \n- The output from flatten layer is fed to this FCL layer.\n\n## Why RMSprop Optimazer ?\n- I used the most used Adam optimizer, but the dev set loss was very high and I can't say that it improved the model performance very much, but RMSprop significantly increased the model performance. \n- When choosing an optimizer, I prefer different models starting from the most used ones, so I discover the most suitable optimizer algorithm for the model.\n\n## Why Categorical Crossentropy Loss ? \n- It computes the cross-entropy loss between true labels and predicted labels. Thıs is most ımportant for us because predicted true label is more important for the model.\n- We have two categories so should use this loss function\n\n## Why Categorical Accuracy Metrics ?\n\n- This metric creates two local variables, total and count that are used to compute the frequency with which y_pred matches y_true. \n* This frequency is ultimately returned as categorical accuracy: an idempotent operation that simply divides total by count.\n- A metric is a function that is used to judge the performance of the model so this metric is more useable for us\n","metadata":{}},{"cell_type":"code","source":"epochs = 50  # for better result increase the epochs\nbatch_size = 64 #for better results you may  decrease the batch_size but training time will increase","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:03:06.212026Z","iopub.execute_input":"2022-04-28T02:03:06.212222Z","iopub.status.idle":"2022-04-28T02:03:06.219215Z","shell.execute_reply.started":"2022-04-28T02:03:06.212197Z","shell.execute_reply":"2022-04-28T02:03:06.218472Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\nearlystop = EarlyStopping(patience=10)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n\ncallbacks = [earlystop, learning_rate_reduction]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:23:28.618059Z","iopub.execute_input":"2022-04-28T02:23:28.618379Z","iopub.status.idle":"2022-04-28T02:23:28.628516Z","shell.execute_reply.started":"2022-04-28T02:23:28.618342Z","shell.execute_reply":"2022-04-28T02:23:28.627782Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# ReduceLRonPlateau\n- Reduce learning rate when a metric has stopped improving.\n- Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. \n- This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n\n# EarlyStopping\n- Stop training when a monitored metric has stopped improving.\n- Assuming the goal of a training is to minimize the loss.\n- With this, the metric to be monitored would be 'loss', and mode would be 'min'. \n- A model.fit() training loop will check at end of every epoch whether the loss is no longer decreasing, considering the min_delta and patience if applicable.\n- Once it's found no longer decreasing, model.stop_training is marked True and the training terminates.\n\n","metadata":{}},{"cell_type":"code","source":"history = model.fit_generator(train_generator,\n                              epochs = epochs,\n                              validation_data = validation_generator,\n                              validation_steps=dev_label.shape[0]//batch_size,\n                              steps_per_epoch=train_label.shape[0] // batch_size,\n                             callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:23:31.300815Z","iopub.execute_input":"2022-04-28T02:23:31.301071Z","iopub.status.idle":"2022-04-28T02:36:28.027908Z","shell.execute_reply.started":"2022-04-28T02:23:31.301041Z","shell.execute_reply":"2022-04-28T02:36:28.027218Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 23, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 23, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:41:59.976332Z","iopub.execute_input":"2022-04-28T02:41:59.977017Z","iopub.status.idle":"2022-04-28T02:42:00.437840Z","shell.execute_reply.started":"2022-04-28T02:41:59.976978Z","shell.execute_reply":"2022-04-28T02:42:00.437170Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:48:49.727106Z","iopub.execute_input":"2022-04-28T02:48:49.727379Z","iopub.status.idle":"2022-04-28T02:48:49.769003Z","shell.execute_reply.started":"2022-04-28T02:48:49.727349Z","shell.execute_reply":"2022-04-28T02:48:49.768348Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Testing Data","metadata":{}},{"cell_type":"code","source":"test_filenames = os.listdir(\"../input/writing/test\")\ntest = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:42:08.665817Z","iopub.execute_input":"2022-04-28T02:42:08.666070Z","iopub.status.idle":"2022-04-28T02:42:08.673431Z","shell.execute_reply.started":"2022-04-28T02:42:08.666042Z","shell.execute_reply":"2022-04-28T02:42:08.672595Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:42:10.729905Z","iopub.execute_input":"2022-04-28T02:42:10.730216Z","iopub.status.idle":"2022-04-28T02:42:10.743897Z","shell.execute_reply.started":"2022-04-28T02:42:10.730181Z","shell.execute_reply":"2022-04-28T02:42:10.743200Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Create Testing Generator","metadata":{}},{"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_gen.flow_from_dataframe(\n    test, \n    \"../input/writing/test\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size= (64,256),\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:42:14.472945Z","iopub.execute_input":"2022-04-28T02:42:14.473294Z","iopub.status.idle":"2022-04-28T02:42:15.576984Z","shell.execute_reply.started":"2022-04-28T02:42:14.473243Z","shell.execute_reply":"2022-04-28T02:42:15.576171Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"predict = model.predict_generator(test_generator)\n\ntest['predicted'] = np.argmax(predict, axis=-1)\n\n# For categorical classification the prediction will come with probability of each category. \n# So we will pick the category that have the highest probability with numpy average max\n\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\n\n# We will convert the predict category back into our generator classes by using train_generator.class_indices. \n# It is the classes that image generator map while converting data into computer vision\n\ntest['predicted'] = test['predicted'].replace(label_map)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:42:16.605777Z","iopub.execute_input":"2022-04-28T02:42:16.606294Z","iopub.status.idle":"2022-04-28T02:42:19.673603Z","shell.execute_reply.started":"2022-04-28T02:42:16.606257Z","shell.execute_reply":"2022-04-28T02:42:19.672823Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:42:19.675286Z","iopub.execute_input":"2022-04-28T02:42:19.675546Z","iopub.status.idle":"2022-04-28T02:42:19.685820Z","shell.execute_reply.started":"2022-04-28T02:42:19.675512Z","shell.execute_reply":"2022-04-28T02:42:19.685146Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# Predicted Result with Images","metadata":{}},{"cell_type":"code","source":"sample_test = test.head(25)\nsample_test.head()\nplt.figure(figsize=(24, 25))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['predicted']\n    img = load_img(\"../input/writing/test/\"+filename, target_size=(64,256))\n    plt.subplot(5, 5, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"Predicted:{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:42:21.535460Z","iopub.execute_input":"2022-04-28T02:42:21.537457Z","iopub.status.idle":"2022-04-28T02:42:24.671733Z","shell.execute_reply.started":"2022-04-28T02:42:21.537409Z","shell.execute_reply":"2022-04-28T02:42:24.667433Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"folder = \"../input/writing/test\"\n\ntest_label = []                        \n\nfor img in os.listdir(folder):\n    if 'handwrit' in img:            \n        test_label.append((img, 1))\n    elif \"printout\" in img:\n        test_label.append((img, 0))\n\ntest_conf= pd.DataFrame(test_label)\ntest_conf= test_conf.rename(columns={0:\"filenames\", 1: \"Real_Label\"}) \ntest_conf= test_conf.drop(labels=[\"filenames\"], axis = 1)\ntest_conf = test_conf.reset_index(drop=True)\ntest_conf[\"Real_Label\"] = test_conf[\"Real_Label\"].replace({0: 'printout', 1: 'handwrit'}) \ntest_conf['Predicted_Label'] = test['predicted'].replace(label_map)\n\ntest_conf['Real_Label'] = test_conf['Real_Label'].replace({ 'handwrit': 1, 'printout': 0 })\ntest_conf['Predicted_Label'] = test_conf['Predicted_Label'].replace({ 'handwrit': 1, 'printout': 0 })\ntest_conf","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:43:19.301446Z","iopub.execute_input":"2022-04-28T02:43:19.301989Z","iopub.status.idle":"2022-04-28T02:43:19.333672Z","shell.execute_reply.started":"2022-04-28T02:43:19.301949Z","shell.execute_reply":"2022-04-28T02:43:19.332972Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"cm_df","metadata":{"execution":{"iopub.status.busy":"2022-04-28T03:37:10.571517Z","iopub.execute_input":"2022-04-28T03:37:10.571791Z","iopub.status.idle":"2022-04-28T03:37:10.582536Z","shell.execute_reply.started":"2022-04-28T03:37:10.571753Z","shell.execute_reply":"2022-04-28T03:37:10.581821Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"matrix","metadata":{"execution":{"iopub.status.busy":"2022-04-28T03:34:19.787948Z","iopub.execute_input":"2022-04-28T03:34:19.788761Z","iopub.status.idle":"2022-04-28T03:34:19.795674Z","shell.execute_reply.started":"2022-04-28T03:34:19.788709Z","shell.execute_reply":"2022-04-28T03:34:19.794977Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"matrix = confusion_matrix(Real_Label,Predicted_Label)\n\ncm_df = pd.DataFrame(matrix,\n                     index = ['PRINTOUT','HANDWRIT'], \n                     columns = ['PRINTOUT','HANDWRIT'])\n\nplt.figure(figsize=(10,10))\nsns.heatmap(cm_df, annot=True)\nplt.title('Confusion Matrix')\nplt.ylabel('TRUE LABEL')\nplt.xlabel('PREDICTED LABEL')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T03:39:38.084856Z","iopub.execute_input":"2022-04-28T03:39:38.085109Z","iopub.status.idle":"2022-04-28T03:39:38.302497Z","shell.execute_reply.started":"2022-04-28T03:39:38.085080Z","shell.execute_reply":"2022-04-28T03:39:38.301793Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Real_Label, Predicted_Label))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:43:31.461639Z","iopub.execute_input":"2022-04-28T02:43:31.461963Z","iopub.status.idle":"2022-04-28T02:43:31.476648Z","shell.execute_reply.started":"2022-04-28T02:43:31.461933Z","shell.execute_reply":"2022-04-28T02:43:31.475867Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nscore = roc_auc_score(Real_Label, Predicted_Label)\nprint(f\"ROC AUC: {score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:43:36.062615Z","iopub.execute_input":"2022-04-28T02:43:36.063149Z","iopub.status.idle":"2022-04-28T02:43:36.070940Z","shell.execute_reply.started":"2022-04-28T02:43:36.063110Z","shell.execute_reply":"2022-04-28T02:43:36.070181Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(Real_Label, Predicted_Label)\nroc_auc = auc(fpr, tpr)\nprecision, recall, thresholds= precision_recall_curve(Real_Label, Predicted_Label)\nauc_score = auc(recall, precision)\nf1 = f1_score(Real_Label, Predicted_Label)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:44:08.214713Z","iopub.execute_input":"2022-04-28T02:44:08.215226Z","iopub.status.idle":"2022-04-28T02:44:08.225464Z","shell.execute_reply.started":"2022-04-28T02:44:08.215188Z","shell.execute_reply":"2022-04-28T02:44:08.224589Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# PRECISION / RECALL","metadata":{}},{"cell_type":"code","source":"no_skill = len(Real_Label[Real_Label==1]) / len(Real_Label)\n\nplt.figure(figsize=(10, 10))\n\nprint('MODEL: f1=%.3f auc=%.3f' % (f1, auc_score))\n\nplt.plot(recall, precision, marker='.', label='PRECISION/RECALL f1=%.3f AUC=%.3f' % (f1, auc_score))\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:44:10.771411Z","iopub.execute_input":"2022-04-28T02:44:10.771954Z","iopub.status.idle":"2022-04-28T02:44:10.972880Z","shell.execute_reply.started":"2022-04-28T02:44:10.771915Z","shell.execute_reply":"2022-04-28T02:44:10.972139Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"ns_probs = [0 for _ in range(len(Predicted_Label))]\nns_auc = roc_auc_score(Predicted_Label, ns_probs)\nns_fpr, ns_tpr, _ = roc_curve(Predicted_Label, ns_probs)\n\nplt.figure(figsize=(10, 10))\n\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label=\"No Skill: ROC AUC=%.3f\" % (ns_auc))\nplt.plot(fpr, tpr, marker='.', label='ROC AUC=%.3f' % (auc_score))\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:44:17.895545Z","iopub.execute_input":"2022-04-28T02:44:17.895796Z","iopub.status.idle":"2022-04-28T02:44:18.110236Z","shell.execute_reply.started":"2022-04-28T02:44:17.895769Z","shell.execute_reply":"2022-04-28T02:44:18.109593Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"# CONCLUSION\n\n### Firstly, ı see the dev set accuracy and loss better than training set. So Why ?\n\n- We may have small validation set (2500)\n- We may have highly unbalanced data in val set but ı do not think so.\n- We use regularization methods such as  Dropout, while model calculate training accuracy it process through regularized model but when it test accuracy on val set, it process your data trough un regularized model. Regularization introduces some noise in loss value during training, because of this training accuracy decreases than expected, but while evaluating the model, model doesn’t use regularization hence no noise, val accuracy doesn’t decrease.\n\n### PRECISION / RECALL , F1 Score\n\n- It describes how good a model is at predicting the positive class. Precision is referred to as the positive predictive value.  This is important for us because the important thing in the model is the true predictive and our precision recall score is good.\n- But dont forget, reviewing bot precision and recall is useful in cases where there is an inbalance in the observations between the two classes. Specifically, there are many examples of no event (class 0 ) and only a few examples. So thıs graph may not useful for us.\n- F1 Score calculates mean of the precision and recall.\n\n### AUC/ROC CURVE\n\n- Roc curve is an evaluation metric for classification problems. It is a probablity curve that plot the TPR (True Positive Rate) against FPR (False Positive Rate) at various threshold values and essentially separates the signal from the noise.\n- The AUC is the meause of the ablity of classifier distinguish between classes and is used as a summary of the ROC curve.\n- ROC Curves should be used when there are queal numbers of observations for each class. So, this graph more usuable for us than Precısıon/Recall curve.\n- ROC/AUC scores seems good so we may say the model can predictive good\n\n### Confusıon Matrix\n\n- When we review the confusıon matrix, we can see the good result there is only FP (False Positive) values have problems. So, our model saw printout data as  handwrit data.\n- Actually this is normal. Because some data are like printout data or noisy data reason for this results.\n\n- We can say the development data of the model should be increased and diversity should be introduced. Also, different methods can be tried by changing the parameters of the model.\n\n","metadata":{}}]}